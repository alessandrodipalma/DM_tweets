{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "import statistics\n",
    "import numpy as np\n",
    "from utilities import get_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_PATH = get_path()"
   ],
   "metadata": {
    "id": "Umr10JpeLQXL"
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_metrics(target, pred, target_labels, set_kind, verbose=True):\n",
    "  print('Accuracy', metrics.accuracy_score(target, pred))\n",
    "  if verbose:\n",
    "    print(f'Precision {set_kind} set ', metrics.precision_score(target, pred, average='weighted'))\n",
    "    print(f'Recall {set_kind} set ', metrics.recall_score(target, pred, average='weighted'))\n",
    "    print(f'F1 score {set_kind} set ', metrics.f1_score(target, pred, average='weighted'))\n",
    "    print(f'Support {set_kind} set ', metrics.precision_recall_fscore_support(target, pred))\n",
    "\n",
    "  print(metrics.classification_report(target, pred, target_names = target_labels))"
   ],
   "metadata": {
    "id": "RKpriQ2iVjlm"
   },
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def confusion_matrix(target, pred):\n",
    "  cm = metrics.confusion_matrix(target, pred)\n",
    "  disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "  disp.plot()\n",
    "  plt.show() "
   ],
   "metadata": {
    "id": "3o7RLboGZr_J"
   },
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cross_validation(model, tr, target):\n",
    "  cv_scores = cross_validate(model, tr, target, cv=5, return_train_score = True, scoring=['accuracy','recall','f1'])\n",
    "\n",
    "  for k in cv_scores.keys():\n",
    "      cv_scores[k] = statistics.mean(cv_scores[k])\n",
    "  return cv_scores\n",
    "#  print('Cross Validation Validation score ', statistics.mean(cv_scores['test_score']))\n",
    "#  print('Cross Validation Train score ', statistics.mean(cv_scores['train_score']))"
   ],
   "metadata": {
    "id": "9OxQ7j_kXmH1"
   },
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_indicators = pd.read_csv(DATA_PATH + 'indicators_clean.csv', sep='#')\n",
    "#df_tweets_ind = pd.read_csv(DATA_PATH+'tweets_with_indicators.csv', sep='#')\n",
    "df_users = pd.read_csv(DATA_PATH + 'users_clean.csv', sep='#')"
   ],
   "metadata": {
    "id": "m4IOAnx9LUt6"
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_users.id = df_users.id.astype(str)\n",
    "df_merge = df_users.merge(df_indicators, left_on='id', right_on='user_id', how='left')"
   ],
   "metadata": {
    "id": "-CmG7XmKL2sK"
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_merge.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyajYHeFMK0x",
    "outputId": "0f5f542b-21fe-44e3-e139-c8fa4b7c8e89"
   },
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   id                                11508 non-null  object \n",
      " 1   name                              11507 non-null  object \n",
      " 2   lang                              11508 non-null  object \n",
      " 3   bot                               11508 non-null  int64  \n",
      " 4   user_subscription                 11508 non-null  object \n",
      " 5   statuses_count                    11508 non-null  float64\n",
      " 6   user_subscription_in_secs         11508 non-null  int64  \n",
      " 7   user_id                           11504 non-null  object \n",
      " 8   n_tweets                          11504 non-null  float64\n",
      " 9   2012_tweets                       11504 non-null  float64\n",
      " 10  2013_tweets                       11504 non-null  float64\n",
      " 11  2014_tweets                       11504 non-null  float64\n",
      " 12  2015_tweets                       11504 non-null  float64\n",
      " 13  2016_tweets                       11504 non-null  float64\n",
      " 14  2017_tweets                       11504 non-null  float64\n",
      " 15  2018_tweets                       11504 non-null  float64\n",
      " 16  2019_tweets                       11504 non-null  float64\n",
      " 17  2020_tweets                       11504 non-null  float64\n",
      " 18  mean_length                       11504 non-null  float64\n",
      " 19  mean_special_chars                11504 non-null  float64\n",
      " 20  publication_date_in_secs_mean     11504 non-null  float64\n",
      " 21  publication_date_in_secs_std      11504 non-null  float64\n",
      " 22  publication_date_in_secs_entropy  11504 non-null  float64\n",
      " 23  retweet_count_mean                11504 non-null  float64\n",
      " 24  retweet_count_std                 11504 non-null  float64\n",
      " 25  retweet_count_entropy             11504 non-null  float64\n",
      " 26  reply_count_mean                  11504 non-null  float64\n",
      " 27  reply_count_std                   11504 non-null  float64\n",
      " 28  reply_count_entropy               11504 non-null  float64\n",
      " 29  favorite_count_mean               11504 non-null  float64\n",
      " 30  favorite_count_std                11504 non-null  float64\n",
      " 31  favorite_count_entropy            11504 non-null  float64\n",
      " 32  num_hashtags_mean                 11504 non-null  float64\n",
      " 33  num_hashtags_std                  11504 non-null  float64\n",
      " 34  num_urls_mean                     11504 non-null  float64\n",
      " 35  num_urls_std                      11504 non-null  float64\n",
      " 36  num_mentions_mean                 11504 non-null  float64\n",
      " 37  num_mentions_std                  11504 non-null  float64\n",
      " 38  tweeting_regularity               11504 non-null  float64\n",
      " 39  max_daily_tweets                  11504 non-null  float64\n",
      " 40  n_tweets_density                  11504 non-null  float64\n",
      "dtypes: float64(34), int64(2), object(5)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop variables which aren't useful for classification purposes\n",
    "df_merge.drop(columns=['id', 'name', 'user_subscription', 'user_id'], inplace=True)\n",
    "df_merge.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ks47Ed2eMMqd",
    "outputId": "5b7f698a-accd-47b6-b3f0-7f4c88566774"
   },
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 37 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   lang                              11508 non-null  object \n",
      " 1   bot                               11508 non-null  int64  \n",
      " 2   statuses_count                    11508 non-null  float64\n",
      " 3   user_subscription_in_secs         11508 non-null  int64  \n",
      " 4   n_tweets                          11504 non-null  float64\n",
      " 5   2012_tweets                       11504 non-null  float64\n",
      " 6   2013_tweets                       11504 non-null  float64\n",
      " 7   2014_tweets                       11504 non-null  float64\n",
      " 8   2015_tweets                       11504 non-null  float64\n",
      " 9   2016_tweets                       11504 non-null  float64\n",
      " 10  2017_tweets                       11504 non-null  float64\n",
      " 11  2018_tweets                       11504 non-null  float64\n",
      " 12  2019_tweets                       11504 non-null  float64\n",
      " 13  2020_tweets                       11504 non-null  float64\n",
      " 14  mean_length                       11504 non-null  float64\n",
      " 15  mean_special_chars                11504 non-null  float64\n",
      " 16  publication_date_in_secs_mean     11504 non-null  float64\n",
      " 17  publication_date_in_secs_std      11504 non-null  float64\n",
      " 18  publication_date_in_secs_entropy  11504 non-null  float64\n",
      " 19  retweet_count_mean                11504 non-null  float64\n",
      " 20  retweet_count_std                 11504 non-null  float64\n",
      " 21  retweet_count_entropy             11504 non-null  float64\n",
      " 22  reply_count_mean                  11504 non-null  float64\n",
      " 23  reply_count_std                   11504 non-null  float64\n",
      " 24  reply_count_entropy               11504 non-null  float64\n",
      " 25  favorite_count_mean               11504 non-null  float64\n",
      " 26  favorite_count_std                11504 non-null  float64\n",
      " 27  favorite_count_entropy            11504 non-null  float64\n",
      " 28  num_hashtags_mean                 11504 non-null  float64\n",
      " 29  num_hashtags_std                  11504 non-null  float64\n",
      " 30  num_urls_mean                     11504 non-null  float64\n",
      " 31  num_urls_std                      11504 non-null  float64\n",
      " 32  num_mentions_mean                 11504 non-null  float64\n",
      " 33  num_mentions_std                  11504 non-null  float64\n",
      " 34  tweeting_regularity               11504 non-null  float64\n",
      " 35  max_daily_tweets                  11504 non-null  float64\n",
      " 36  n_tweets_density                  11504 non-null  float64\n",
      "dtypes: float64(34), int64(2), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def discretize_column(df, column_name):\n",
    "    #get the unique variable's values\n",
    "    values = df[column_name].unique()\n",
    "\n",
    "    d = dict( (el, i) for i, el in enumerate(values) )\n",
    "\n",
    "    df[column_name + '_discr'] = df[column_name].apply(lambda x: d[x])"
   ],
   "metadata": {
    "id": "-nKMlYUmNKdK"
   },
   "execution_count": 77,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert lang column to numbers (e.g. en = 0, it = 1, etc.)\n",
    "discretize_column(df_merge, 'lang')\n",
    "\n",
    "# Drop original lang column\n",
    "df_merge.drop(columns=['lang'], inplace=True)\n",
    "df_merge"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "eJa0XfErNf0p",
    "outputId": "86a6c44c-e991-4928-f1b1-eb5a3eb9e563"
   },
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "       bot  statuses_count  user_subscription_in_secs  n_tweets  2012_tweets  \\\n0        1            76.0        1550858442000000000     119.0          0.0   \n1        0            54.0        1551150152000000000     106.0          0.0   \n2        1             3.0        1430377796000000000       3.0          0.0   \n3        1            50.0        1484707758000000000    1269.0          0.0   \n4        0          7085.0        1560886221000000000    3234.0          0.0   \n...    ...             ...                        ...       ...          ...   \n11503    0          1126.0        1575033362000000000     996.0          0.0   \n11504    0          3024.0        1524798118000000000    1854.0          0.0   \n11505    0             6.0        1427648484000000000       6.0          0.0   \n11506    1            42.0        1552445053000000000      95.0          0.0   \n11507    0          5279.0        1510269856000000000    3268.0          0.0   \n\n       2013_tweets  2014_tweets  2015_tweets  2016_tweets  2017_tweets  ...  \\\n0              0.0          0.0          0.0          0.0          0.0  ...   \n1              0.0          0.0          0.0          0.0          0.0  ...   \n2              0.0          0.0          0.0          3.0          0.0  ...   \n3              0.0          0.0          0.0          0.0          1.0  ...   \n4              0.0          0.0          0.0          0.0          0.0  ...   \n...            ...          ...          ...          ...          ...  ...   \n11503          0.0          0.0          0.0          0.0          0.0  ...   \n11504          0.0          0.0          0.0          0.0          0.0  ...   \n11505          0.0          0.0          1.0          2.0          3.0  ...   \n11506          0.0          0.0          0.0          0.0          0.0  ...   \n11507          0.0          0.0          0.0          0.0          0.0  ...   \n\n       num_hashtags_mean  num_hashtags_std  num_urls_mean  num_urls_std  \\\n0               0.109244          0.465594       0.000000      0.000000   \n1               0.028302          0.166622       0.000000      0.000000   \n2               0.000000          0.000000       0.000000      0.000000   \n3               0.084318          0.469897       0.023641      0.151987   \n4               0.132962          0.415753       0.000928      0.030448   \n...                  ...               ...            ...           ...   \n11503           0.216867          0.614037       0.027108      0.168553   \n11504           0.129989          0.438114       0.100324      0.302303   \n11505           0.333333          0.516398       0.666667      0.516398   \n11506           0.010526          0.102598       0.000000      0.000000   \n11507           0.045594          0.217259       0.013770      0.116552   \n\n       num_mentions_mean  num_mentions_std  tweeting_regularity  \\\n0               0.294118          0.457572             2.458470   \n1               0.358491          0.481835             2.504295   \n2               0.000000          0.000000             0.060681   \n3               0.007092          0.108533             1.657428   \n4               0.528139          0.634101             7.637613   \n...                  ...               ...                  ...   \n11503           0.745984          0.860486             4.828845   \n11504           0.544229          0.720479             4.181057   \n11505           0.333333          0.516398             0.919460   \n11506           0.400000          0.492497             2.421923   \n11507           0.761016          0.745634             5.312883   \n\n       max_daily_tweets  n_tweets_density  lang_discr  \n0                  17.0      7.424137e-10           0  \n1                  18.0      6.742423e-10           0  \n2                   2.0      7.349446e-12           0  \n3                 130.0      1.231306e-09           1  \n4                  47.0      1.014485e-08           0  \n...                 ...               ...         ...  \n11503              52.0      6.419927e-09           0  \n11504              83.0      2.528313e-09           0  \n11505               2.0      6.221464e-12           4  \n11506              10.0      6.613163e-10           0  \n11507             179.0      3.611992e-09           0  \n\n[11508 rows x 37 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bot</th>\n      <th>statuses_count</th>\n      <th>user_subscription_in_secs</th>\n      <th>n_tweets</th>\n      <th>2012_tweets</th>\n      <th>2013_tweets</th>\n      <th>2014_tweets</th>\n      <th>2015_tweets</th>\n      <th>2016_tweets</th>\n      <th>2017_tweets</th>\n      <th>...</th>\n      <th>num_hashtags_mean</th>\n      <th>num_hashtags_std</th>\n      <th>num_urls_mean</th>\n      <th>num_urls_std</th>\n      <th>num_mentions_mean</th>\n      <th>num_mentions_std</th>\n      <th>tweeting_regularity</th>\n      <th>max_daily_tweets</th>\n      <th>n_tweets_density</th>\n      <th>lang_discr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>76.0</td>\n      <td>1550858442000000000</td>\n      <td>119.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.109244</td>\n      <td>0.465594</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.294118</td>\n      <td>0.457572</td>\n      <td>2.458470</td>\n      <td>17.0</td>\n      <td>7.424137e-10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>54.0</td>\n      <td>1551150152000000000</td>\n      <td>106.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.028302</td>\n      <td>0.166622</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.358491</td>\n      <td>0.481835</td>\n      <td>2.504295</td>\n      <td>18.0</td>\n      <td>6.742423e-10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>1430377796000000000</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.060681</td>\n      <td>2.0</td>\n      <td>7.349446e-12</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>50.0</td>\n      <td>1484707758000000000</td>\n      <td>1269.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.084318</td>\n      <td>0.469897</td>\n      <td>0.023641</td>\n      <td>0.151987</td>\n      <td>0.007092</td>\n      <td>0.108533</td>\n      <td>1.657428</td>\n      <td>130.0</td>\n      <td>1.231306e-09</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>7085.0</td>\n      <td>1560886221000000000</td>\n      <td>3234.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.132962</td>\n      <td>0.415753</td>\n      <td>0.000928</td>\n      <td>0.030448</td>\n      <td>0.528139</td>\n      <td>0.634101</td>\n      <td>7.637613</td>\n      <td>47.0</td>\n      <td>1.014485e-08</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11503</th>\n      <td>0</td>\n      <td>1126.0</td>\n      <td>1575033362000000000</td>\n      <td>996.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.216867</td>\n      <td>0.614037</td>\n      <td>0.027108</td>\n      <td>0.168553</td>\n      <td>0.745984</td>\n      <td>0.860486</td>\n      <td>4.828845</td>\n      <td>52.0</td>\n      <td>6.419927e-09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11504</th>\n      <td>0</td>\n      <td>3024.0</td>\n      <td>1524798118000000000</td>\n      <td>1854.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.129989</td>\n      <td>0.438114</td>\n      <td>0.100324</td>\n      <td>0.302303</td>\n      <td>0.544229</td>\n      <td>0.720479</td>\n      <td>4.181057</td>\n      <td>83.0</td>\n      <td>2.528313e-09</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11505</th>\n      <td>0</td>\n      <td>6.0</td>\n      <td>1427648484000000000</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>0.516398</td>\n      <td>0.666667</td>\n      <td>0.516398</td>\n      <td>0.333333</td>\n      <td>0.516398</td>\n      <td>0.919460</td>\n      <td>2.0</td>\n      <td>6.221464e-12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>11506</th>\n      <td>1</td>\n      <td>42.0</td>\n      <td>1552445053000000000</td>\n      <td>95.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.010526</td>\n      <td>0.102598</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.400000</td>\n      <td>0.492497</td>\n      <td>2.421923</td>\n      <td>10.0</td>\n      <td>6.613163e-10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11507</th>\n      <td>0</td>\n      <td>5279.0</td>\n      <td>1510269856000000000</td>\n      <td>3268.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.045594</td>\n      <td>0.217259</td>\n      <td>0.013770</td>\n      <td>0.116552</td>\n      <td>0.761016</td>\n      <td>0.745634</td>\n      <td>5.312883</td>\n      <td>179.0</td>\n      <td>3.611992e-09</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11508 rows × 37 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Eliminate NaN values\n",
    "df_merge = df_merge.fillna(value=0)"
   ],
   "metadata": {
    "id": "rtgfC-PgUlXc"
   },
   "execution_count": 79,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "df_merge.replace(-np.inf, np.finfo(np.float32).min, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "df_merge.replace(np.inf, np.finfo(np.float32).max, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11508 entries, 0 to 11507\n",
      "Data columns (total 37 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   bot                               11508 non-null  int64  \n",
      " 1   statuses_count                    11508 non-null  float64\n",
      " 2   user_subscription_in_secs         11508 non-null  int64  \n",
      " 3   n_tweets                          11508 non-null  float64\n",
      " 4   2012_tweets                       11508 non-null  float64\n",
      " 5   2013_tweets                       11508 non-null  float64\n",
      " 6   2014_tweets                       11508 non-null  float64\n",
      " 7   2015_tweets                       11508 non-null  float64\n",
      " 8   2016_tweets                       11508 non-null  float64\n",
      " 9   2017_tweets                       11508 non-null  float64\n",
      " 10  2018_tweets                       11508 non-null  float64\n",
      " 11  2019_tweets                       11508 non-null  float64\n",
      " 12  2020_tweets                       11508 non-null  float64\n",
      " 13  mean_length                       11508 non-null  float64\n",
      " 14  mean_special_chars                11508 non-null  float64\n",
      " 15  publication_date_in_secs_mean     11508 non-null  float64\n",
      " 16  publication_date_in_secs_std      11508 non-null  float64\n",
      " 17  publication_date_in_secs_entropy  11508 non-null  float64\n",
      " 18  retweet_count_mean                11508 non-null  float64\n",
      " 19  retweet_count_std                 11508 non-null  float64\n",
      " 20  retweet_count_entropy             11508 non-null  float64\n",
      " 21  reply_count_mean                  11508 non-null  float64\n",
      " 22  reply_count_std                   11508 non-null  float64\n",
      " 23  reply_count_entropy               11508 non-null  float64\n",
      " 24  favorite_count_mean               11508 non-null  float64\n",
      " 25  favorite_count_std                11508 non-null  float64\n",
      " 26  favorite_count_entropy            11508 non-null  float64\n",
      " 27  num_hashtags_mean                 11508 non-null  float64\n",
      " 28  num_hashtags_std                  11508 non-null  float64\n",
      " 29  num_urls_mean                     11508 non-null  float64\n",
      " 30  num_urls_std                      11508 non-null  float64\n",
      " 31  num_mentions_mean                 11508 non-null  float64\n",
      " 32  num_mentions_std                  11508 non-null  float64\n",
      " 33  tweeting_regularity               11508 non-null  float64\n",
      " 34  max_daily_tweets                  11508 non-null  float64\n",
      " 35  n_tweets_density                  11508 non-null  float64\n",
      " 36  lang_discr                        11508 non-null  int64  \n",
      "dtypes: float64(34), int64(3)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_merge.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "tr, ts, tr_target, ts_target = train_test_split(df_merge.drop(columns='bot'), df_merge['bot'], stratify =df_merge['bot'], test_size=0.20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in Training set: 7364\n",
      "Number of samples in Validation set: 1842\n",
      "Number of samples in Test set: 2302\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of samples in Training set:', len(tr))\n",
    "print(f'Number of samples in Test set:', len(ts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree"
   ],
   "metadata": {
    "id": "5RExXIP7SSm8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'criterion': ['gini','entropy','log_loss'],\n",
    "    'splitter': ['random','best'],\n",
    "    'max_depth': [4,8,16,32,64,None],\n",
    "    'min_samples_split': [2,4,8,16,32],\n",
    "    'min_samples_leaf': [1,2,4,8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state': [42],\n",
    "    'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.0, 1e-2],\n",
    "}\n",
    "\n",
    "d_tree = DecisionTreeClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "gs = GridSearchCV(d_tree, param_grid=parameters, scoring=['accuracy','precision', 'recall', 'f1'], verbose=3, refit=False, n_jobs=6, return_train_score=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4320 candidates, totalling 21600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "7200 fits failed out of a total of 21600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72582988 0.81979729 0.72582988 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.72633655 0.82186981 0.72633655 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.6927623  0.75315322 0.6927623  ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.69315739 0.75457115 0.69315739 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.87048273 0.98364935 0.87048273 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.87001362 0.98537313 0.87001362 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77073528 0.85305637 0.77073528 ...        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.77107933 0.85466103 0.77107933 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=DecisionTreeClassifier(max_depth=10, min_samples_leaf=3,\n                                              min_samples_split=5),\n             n_jobs=6,\n             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n                         'max_depth': [4, 8, 16, 32, 64, None],\n                         'max_features': ['sqrt', 'log2', None],\n                         'max_leaf_nodes': [None],\n                         'min_impurity_decrease': [0.0, 0.01],\n                         'min_samples_leaf': [1, 2, 4, 8],\n                         'min_samples_split': [2, 4, 8, 16, 32],\n                         'random_state': [42], 'splitter': ['random', 'best']},\n             refit=False, return_train_score=True,\n             scoring=['accuracy', 'precision', 'recall', 'f1'], verbose=3)"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(tr, tr_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(gs.cv_results_)\n",
    "results_df.to_csv(\"classification/decision_tree/gs_results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                   params  \\\n2879     {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n2849     {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 1, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n1657        {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}   \n1659        {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n1661         {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}   \n...                                                                                                                                                                                                                   ...   \n4315     {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 8, 'random_state': 42, 'splitter': 'best'}   \n4316  {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'random'}   \n4317    {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}   \n4318  {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'random'}   \n4319    {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n\n      mean_train_accuracy  mean_train_precision  mean_train_recall  \\\n2879              0.85918              0.794242            0.99208   \n2849              0.85918              0.794242            0.99208   \n1657              0.85918              0.794242            0.99208   \n1659              0.85918              0.794242            0.99208   \n1661              0.85918              0.794242            0.99208   \n...                   ...                   ...                ...   \n4315                  NaN                   NaN                NaN   \n4316                  NaN                   NaN                NaN   \n4317                  NaN                   NaN                NaN   \n4318                  NaN                   NaN                NaN   \n4319                  NaN                   NaN                NaN   \n\n      mean_train_f1  mean_test_accuracy  mean_test_precision  \\\n2879       0.882203            0.859178             0.794396   \n2849       0.882203            0.859178             0.794396   \n1657       0.882203            0.859178             0.794396   \n1659       0.882203            0.859178             0.794396   \n1661       0.882203            0.859178             0.794396   \n...             ...                 ...                  ...   \n4315            NaN                 NaN                  NaN   \n4316            NaN                 NaN                  NaN   \n4317            NaN                 NaN                  NaN   \n4318            NaN                 NaN                  NaN   \n4319            NaN                 NaN                  NaN   \n\n      mean_test_recall  mean_test_f1  \n2879          0.992079      0.882259  \n2849          0.992079      0.882259  \n1657          0.992079      0.882259  \n1659          0.992079      0.882259  \n1661          0.992079      0.882259  \n...                ...           ...  \n4315               NaN           NaN  \n4316               NaN           NaN  \n4317               NaN           NaN  \n4318               NaN           NaN  \n4319               NaN           NaN  \n\n[4320 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_train_accuracy</th>\n      <th>mean_train_precision</th>\n      <th>mean_train_recall</th>\n      <th>mean_train_f1</th>\n      <th>mean_test_accuracy</th>\n      <th>mean_test_precision</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2879</th>\n      <td>{'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>2849</th>\n      <td>{'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 1, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1657</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1659</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1661</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4315</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 8, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4316</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'random'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4317</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4318</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'random'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4319</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4320 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "results_df.sort_values(by='mean_test_f1',ascending=False)[['params','mean_train_accuracy','mean_train_precision','mean_train_recall','mean_train_f1',\n",
    "            'mean_test_accuracy','mean_test_precision','mean_test_recall','mean_test_f1']]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "params = results_df.sort_values(by='mean_test_f1',ascending=False)['params'].head(1).reset_index().loc[0][1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeClassifier(**params)\n",
    "d_tree = d_tree.fit(tr, tr_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(d_tree, out_file=None, feature_names=list(ts.columns), filled=True, rounded=True, class_names=['genuine user','bot'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "with open('./classification/decision_tree/dtree_graph.png','wb') as png:\n",
    "    png.write(Image(graph.create_png()).data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8514335360556038\n",
      "Precision test set  0.8800523354494986\n",
      "Recall test set  0.8514335360556038\n",
      "F1 score test set  0.8469991597026366\n",
      "Support test set  (array([0.98807947, 0.78474467]), array([0.69138091, 0.99264105]), array([0.81352236, 0.8765343 ]), array([1079, 1223], dtype=int64))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "genuine_user       0.99      0.69      0.81      1079\n",
      "         bot       0.78      0.99      0.88      1223\n",
      "\n",
      "    accuracy                           0.85      2302\n",
      "   macro avg       0.89      0.84      0.85      2302\n",
      "weighted avg       0.88      0.85      0.85      2302\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts_pred = d_tree.predict(ts)\n",
    "get_metrics(ts_target, ts_pred, ['genuine_user','bot'],'test')\n",
    "confusion_matrix(ts_target, ts_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: scatter plots"
   ],
   "metadata": {
    "id": "e-DiQiFTdHX_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Example\n",
    "plt.scatter(df_users[df_users['bot'] == 0]['created_at_conv'], \n",
    "            df_users[df_users['bot'] == 0]['lang'], color='g', marker='*', label='Non-bot user')\n",
    "plt.scatter(df_users[df_users['bot'] == 1]['created_at_conv'], \n",
    "            df_users[df_users['bot'] == 1]['lang'], color='r', marker='2', label='Bot user')\n",
    "plt.xlabel('created_at')\n",
    "plt.ylabel('lang')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "h4-gsmHCfCNa"
   },
   "execution_count": 152,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'created_at_conv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'created_at_conv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [152]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Example\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(\u001B[43mdf_users\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf_users\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbot\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcreated_at_conv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, \n\u001B[0;32m      3\u001B[0m             df_users[df_users[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbot\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m], color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mg\u001B[39m\u001B[38;5;124m'\u001B[39m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNon-bot user\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(df_users[df_users[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbot\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreated_at_conv\u001B[39m\u001B[38;5;124m'\u001B[39m], \n\u001B[0;32m      5\u001B[0m             df_users[df_users[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbot\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m'\u001B[39m], color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m, marker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBot user\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreated_at\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'created_at_conv'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes"
   ],
   "metadata": {
    "id": "7hpJISxodOgL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "multinomial_nb = MultinomialNB()\n",
    "labels = ['genuine user','bot']\n",
    "parameters = {\n",
    "    'alpha':[0.25,0.5,0.75,1, 2],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(multinomial_nb, param_grid=parameters, scoring=['accuracy','precision', 'recall', 'f1'], verbose=3, refit=False, n_jobs=6, return_train_score=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "fPMobN77V5ZR",
    "outputId": "23f24cd9-30de-46f9-8b09-bdab6a512279"
   },
   "execution_count": 172,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 690, in fit\n",
      "    self._count(X, Y)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 863, in _count\n",
      "    check_non_negative(X, \"MultinomialNB (input X)\")\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1249, in check_non_negative\n",
      "    raise ValueError(\"Negative values in data passed to %s\" % whom)\n",
      "ValueError: Negative values in data passed to MultinomialNB (input X)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=MultinomialNB(), n_jobs=6,\n             param_grid={'alpha': [0.25, 0.5, 0.75, 1, 2],\n                         'fit_prior': [True, False]},\n             refit=False, return_train_score=True,\n             scoring=['accuracy', 'precision', 'recall', 'f1'], verbose=3)"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(tr, tr_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame(gs.cv_results_)\n",
    "results_df.to_csv(\"classification/mn_naive_bayes/gs_results.csv\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uH2Jcohzda7o",
    "outputId": "4579f9a1-4760-42cb-9843-b709440763fc"
   },
   "execution_count": 174,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "                                params  mean_train_accuracy  \\\n0   {'alpha': 0.25, 'fit_prior': True}                  NaN   \n1  {'alpha': 0.25, 'fit_prior': False}                  NaN   \n2    {'alpha': 0.5, 'fit_prior': True}                  NaN   \n3   {'alpha': 0.5, 'fit_prior': False}                  NaN   \n4   {'alpha': 0.75, 'fit_prior': True}                  NaN   \n5  {'alpha': 0.75, 'fit_prior': False}                  NaN   \n6      {'alpha': 1, 'fit_prior': True}                  NaN   \n7     {'alpha': 1, 'fit_prior': False}                  NaN   \n8      {'alpha': 2, 'fit_prior': True}                  NaN   \n9     {'alpha': 2, 'fit_prior': False}                  NaN   \n\n   mean_train_precision  mean_train_recall  mean_train_f1  mean_test_accuracy  \\\n0                   NaN                NaN            NaN                 NaN   \n1                   NaN                NaN            NaN                 NaN   \n2                   NaN                NaN            NaN                 NaN   \n3                   NaN                NaN            NaN                 NaN   \n4                   NaN                NaN            NaN                 NaN   \n5                   NaN                NaN            NaN                 NaN   \n6                   NaN                NaN            NaN                 NaN   \n7                   NaN                NaN            NaN                 NaN   \n8                   NaN                NaN            NaN                 NaN   \n9                   NaN                NaN            NaN                 NaN   \n\n   mean_test_precision  mean_test_recall  mean_test_f1  \n0                  NaN               NaN           NaN  \n1                  NaN               NaN           NaN  \n2                  NaN               NaN           NaN  \n3                  NaN               NaN           NaN  \n4                  NaN               NaN           NaN  \n5                  NaN               NaN           NaN  \n6                  NaN               NaN           NaN  \n7                  NaN               NaN           NaN  \n8                  NaN               NaN           NaN  \n9                  NaN               NaN           NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_train_accuracy</th>\n      <th>mean_train_precision</th>\n      <th>mean_train_recall</th>\n      <th>mean_train_f1</th>\n      <th>mean_test_accuracy</th>\n      <th>mean_test_precision</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'alpha': 0.25, 'fit_prior': True}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'alpha': 0.25, 'fit_prior': False}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'alpha': 0.5, 'fit_prior': True}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'alpha': 0.5, 'fit_prior': False}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'alpha': 0.75, 'fit_prior': True}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'alpha': 0.75, 'fit_prior': False}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>{'alpha': 1, 'fit_prior': True}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>{'alpha': 1, 'fit_prior': False}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>{'alpha': 2, 'fit_prior': True}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>{'alpha': 2, 'fit_prior': False}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\n",
    "    ['params', 'mean_train_accuracy', 'mean_train_precision', 'mean_train_recall', 'mean_train_f1',\n",
    "     'mean_test_accuracy', 'mean_test_precision', 'mean_test_recall', 'mean_test_f1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "id": "H0waTU7ZdyIm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "'  \\n\"max_depth\": [None] + list(range(5,100,10)),\\n    #\"min_samples_split\": [2,4,8,16,32,64],\\n    \"min_samples_split\": [2,16,64],\\n    #\"min_samples_leaf\": [2,4,8,16,32,64,128],\\n    \"min_samples_leaf\": [2,16,64,128],\\n    \"max_features\":[\"auto\",\"sqrt\",\"log2\",None],\\n    \"max_leaf_nodes\":[None] + list(range(1,10,2)),\\n    \"min_impurity_decrease\": 0.1 * np.array(range(1,5))\\n'"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": range(50,500,100),\n",
    "    \"criterion\": [\"gini\",\"entropy\",\"log_loss\"],\n",
    "    \"max_depth\": [None] + list(range(5,100,10)),\n",
    "    \"min_samples_split\": [2,4,8,16,32,64],\n",
    "    \"min_samples_leaf\": [2,4,8,16,32,64,128],\n",
    "    \"max_features\":[\"auto\",\"sqrt\",\"log2\",None],\n",
    "    \"max_leaf_nodes\":[None] + list(range(1,10,2)),\n",
    "    \"min_impurity_decrease\": 0.1 * np.array(range(1,5))\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "r_forest = RandomForestClassifier()\n",
    "gs = GridSearchCV(r_forest,param_grid=parameters, scoring=['accuracy','recall','f1'], verbose=3,refit=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END criterion=gini, n_estimators=50; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.985) total time=   0.6s\n",
      "[CV 2/5] END criterion=gini, n_estimators=50; accuracy: (test=0.856) f1: (test=0.879) recall: (test=0.987) total time=   0.5s\n",
      "[CV 3/5] END criterion=gini, n_estimators=50; accuracy: (test=0.851) f1: (test=0.876) recall: (test=0.987) total time=   0.6s\n",
      "[CV 4/5] END criterion=gini, n_estimators=50; accuracy: (test=0.845) f1: (test=0.872) recall: (test=0.989) total time=   0.5s\n",
      "[CV 5/5] END criterion=gini, n_estimators=50; accuracy: (test=0.862) f1: (test=0.883) recall: (test=0.982) total time=   0.5s\n",
      "[CV 1/5] END criterion=gini, n_estimators=150; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.990) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, n_estimators=150; accuracy: (test=0.852) f1: (test=0.876) recall: (test=0.985) total time=   1.5s\n",
      "[CV 3/5] END criterion=gini, n_estimators=150; accuracy: (test=0.854) f1: (test=0.879) recall: (test=0.990) total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, n_estimators=150; accuracy: (test=0.849) f1: (test=0.875) recall: (test=0.994) total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, n_estimators=150; accuracy: (test=0.865) f1: (test=0.885) recall: (test=0.981) total time=   1.5s\n",
      "[CV 1/5] END criterion=gini, n_estimators=250; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.989) total time=   2.6s\n",
      "[CV 2/5] END criterion=gini, n_estimators=250; accuracy: (test=0.852) f1: (test=0.876) recall: (test=0.985) total time=   2.6s\n",
      "[CV 3/5] END criterion=gini, n_estimators=250; accuracy: (test=0.854) f1: (test=0.878) recall: (test=0.993) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, n_estimators=250; accuracy: (test=0.846) f1: (test=0.873) recall: (test=0.992) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, n_estimators=250; accuracy: (test=0.866) f1: (test=0.886) recall: (test=0.982) total time=   2.6s\n",
      "[CV 1/5] END criterion=gini, n_estimators=350; accuracy: (test=0.856) f1: (test=0.879) recall: (test=0.991) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, n_estimators=350; accuracy: (test=0.854) f1: (test=0.878) recall: (test=0.986) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, n_estimators=350; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.990) total time=   3.6s\n",
      "[CV 4/5] END criterion=gini, n_estimators=350; accuracy: (test=0.847) f1: (test=0.873) recall: (test=0.992) total time=   3.8s\n",
      "[CV 5/5] END criterion=gini, n_estimators=350; accuracy: (test=0.867) f1: (test=0.887) recall: (test=0.984) total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, n_estimators=450; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.990) total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, n_estimators=450; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.984) total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, n_estimators=450; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.994) total time=   4.5s\n",
      "[CV 4/5] END criterion=gini, n_estimators=450; accuracy: (test=0.849) f1: (test=0.875) recall: (test=0.995) total time=   4.7s\n",
      "[CV 5/5] END criterion=gini, n_estimators=450; accuracy: (test=0.867) f1: (test=0.887) recall: (test=0.985) total time=   4.5s\n",
      "[CV 1/5] END criterion=entropy, n_estimators=50; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.989) total time=   0.7s\n",
      "[CV 2/5] END criterion=entropy, n_estimators=50; accuracy: (test=0.849) f1: (test=0.874) recall: (test=0.981) total time=   0.7s\n",
      "[CV 3/5] END criterion=entropy, n_estimators=50; accuracy: (test=0.853) f1: (test=0.878) recall: (test=0.993) total time=   0.7s\n",
      "[CV 4/5] END criterion=entropy, n_estimators=50; accuracy: (test=0.848) f1: (test=0.874) recall: (test=0.993) total time=   0.7s\n",
      "[CV 5/5] END criterion=entropy, n_estimators=50; accuracy: (test=0.865) f1: (test=0.885) recall: (test=0.979) total time=   0.7s\n",
      "[CV 1/5] END criterion=entropy, n_estimators=150; accuracy: (test=0.855) f1: (test=0.879) recall: (test=0.990) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, n_estimators=150; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.986) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, n_estimators=150; accuracy: (test=0.856) f1: (test=0.880) recall: (test=0.993) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, n_estimators=150; accuracy: (test=0.849) f1: (test=0.875) recall: (test=0.994) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, n_estimators=150; accuracy: (test=0.868) f1: (test=0.888) recall: (test=0.983) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, n_estimators=250; accuracy: (test=0.856) f1: (test=0.879) recall: (test=0.990) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, n_estimators=250; accuracy: (test=0.852) f1: (test=0.876) recall: (test=0.984) total time=   3.4s\n",
      "[CV 3/5] END criterion=entropy, n_estimators=250; accuracy: (test=0.856) f1: (test=0.880) recall: (test=0.991) total time=   3.6s\n",
      "[CV 4/5] END criterion=entropy, n_estimators=250; accuracy: (test=0.850) f1: (test=0.876) recall: (test=0.995) total time=   9.1s\n",
      "[CV 5/5] END criterion=entropy, n_estimators=250; accuracy: (test=0.866) f1: (test=0.886) recall: (test=0.984) total time=   7.5s\n",
      "[CV 1/5] END criterion=entropy, n_estimators=350; accuracy: (test=0.856) f1: (test=0.879) recall: (test=0.991) total time=  10.2s\n",
      "[CV 2/5] END criterion=entropy, n_estimators=350; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.983) total time=   9.0s\n",
      "[CV 3/5] END criterion=entropy, n_estimators=350; accuracy: (test=0.856) f1: (test=0.880) recall: (test=0.994) total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, n_estimators=350; accuracy: (test=0.850) f1: (test=0.876) recall: (test=0.996) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, n_estimators=350; accuracy: (test=0.866) f1: (test=0.886) recall: (test=0.983) total time=  11.4s\n",
      "[CV 1/5] END criterion=entropy, n_estimators=450; accuracy: (test=0.856) f1: (test=0.879) recall: (test=0.991) total time=  11.9s\n",
      "[CV 2/5] END criterion=entropy, n_estimators=450; accuracy: (test=0.853) f1: (test=0.877) recall: (test=0.983) total time=  11.2s\n",
      "[CV 3/5] END criterion=entropy, n_estimators=450; accuracy: (test=0.856) f1: (test=0.880) recall: (test=0.993) total time=  15.4s\n",
      "[CV 4/5] END criterion=entropy, n_estimators=450; accuracy: (test=0.849) f1: (test=0.875) recall: (test=0.994) total time=  13.9s\n",
      "[CV 5/5] END criterion=entropy, n_estimators=450; accuracy: (test=0.865) f1: (test=0.885) recall: (test=0.981) total time=   9.0s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=50; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=50; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=50; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=50; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=50; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=150; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=150; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=150; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=150; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=150; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=250; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=250; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=250; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=250; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=250; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=350; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=350; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=350; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=350; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=350; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 1/5] END criterion=log_loss, n_estimators=450; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 2/5] END criterion=log_loss, n_estimators=450; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 3/5] END criterion=log_loss, n_estimators=450; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 4/5] END criterion=log_loss, n_estimators=450; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n",
      "[CV 5/5] END criterion=log_loss, n_estimators=450; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.85357377 0.85487729 0.8547686  0.85531172 0.85574633 0.85422542\n",
      " 0.85618087 0.85596354 0.85607218 0.855529          nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.98569364 0.98773737 0.98794145 0.98835045 0.98937274 0.9867153\n",
      " 0.98896353 0.98855537 0.98916824 0.98814595        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.87741275 0.87859477 0.87854639 0.87898732 0.87941192 0.87800882\n",
      " 0.87969392 0.87947904 0.87962597 0.87911549        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=RandomForestClassifier(min_samples_leaf=4,\n                                              min_samples_split=5,\n                                              n_estimators=200),\n             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n                         'n_estimators': range(50, 500, 100)},\n             refit=False, scoring=['accuracy', 'recall', 'f1'], verbose=3)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(tr,tr_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.608557      0.064217         0.026259        0.008374   \n1        1.539208      0.027788         0.051781        0.002160   \n2        2.552853      0.081574         0.081552        0.002973   \n3        3.694177      0.132688         0.116957        0.007010   \n4        4.539945      0.106185         0.147498        0.004690   \n5        0.747248      0.010979         0.020513        0.000602   \n6        2.154744      0.074342         0.050961        0.000738   \n7        5.432840      2.369643         0.115296        0.042988   \n8        9.816453      0.958650         0.249620        0.047486   \n9       12.076668      2.160699         0.281048        0.082666   \n10       0.029596      0.003211         0.000000        0.000000   \n11       0.081283      0.007692         0.000000        0.000000   \n12       0.132896      0.011402         0.000000        0.000000   \n13       0.171306      0.012790         0.000000        0.000000   \n14       0.234864      0.010317         0.000000        0.000000   \n\n   param_criterion param_n_estimators  \\\n0             gini                 50   \n1             gini                150   \n2             gini                250   \n3             gini                350   \n4             gini                450   \n5          entropy                 50   \n6          entropy                150   \n7          entropy                250   \n8          entropy                350   \n9          entropy                450   \n10        log_loss                 50   \n11        log_loss                150   \n12        log_loss                250   \n13        log_loss                350   \n14        log_loss                450   \n\n                                            params  split0_test_accuracy  \\\n0        {'criterion': 'gini', 'n_estimators': 50}              0.853420   \n1       {'criterion': 'gini', 'n_estimators': 150}              0.854506   \n2       {'criterion': 'gini', 'n_estimators': 250}              0.855049   \n3       {'criterion': 'gini', 'n_estimators': 350}              0.855592   \n4       {'criterion': 'gini', 'n_estimators': 450}              0.855049   \n5     {'criterion': 'entropy', 'n_estimators': 50}              0.855049   \n6    {'criterion': 'entropy', 'n_estimators': 150}              0.855049   \n7    {'criterion': 'entropy', 'n_estimators': 250}              0.855592   \n8    {'criterion': 'entropy', 'n_estimators': 350}              0.855592   \n9    {'criterion': 'entropy', 'n_estimators': 450}              0.855592   \n10   {'criterion': 'log_loss', 'n_estimators': 50}                   NaN   \n11  {'criterion': 'log_loss', 'n_estimators': 150}                   NaN   \n12  {'criterion': 'log_loss', 'n_estimators': 250}                   NaN   \n13  {'criterion': 'log_loss', 'n_estimators': 350}                   NaN   \n14  {'criterion': 'log_loss', 'n_estimators': 450}                   NaN   \n\n    split1_test_accuracy  split2_test_accuracy  ...  std_test_recall  \\\n0               0.856056              0.851168  ...         0.002421   \n1               0.851711              0.854427  ...         0.004618   \n2               0.852254              0.853884  ...         0.004260   \n3               0.853884              0.852797  ...         0.003142   \n4               0.852797              0.854970  ...         0.004597   \n5               0.848995              0.853341  ...         0.006065   \n6               0.853341              0.855513  ...         0.004260   \n7               0.852254              0.856056  ...         0.004355   \n8               0.853341              0.856056  ...         0.005583   \n9               0.852797              0.855513  ...         0.005471   \n10                   NaN                   NaN  ...              NaN   \n11                   NaN                   NaN  ...              NaN   \n12                   NaN                   NaN  ...              NaN   \n13                   NaN                   NaN  ...              NaN   \n14                   NaN                   NaN  ...              NaN   \n\n    rank_test_recall  split0_test_f1  split1_test_f1  split2_test_f1  \\\n0                 10        0.877161        0.879381        0.875793   \n1                  8        0.878513        0.875965        0.878513   \n2                  7        0.878802        0.876364        0.878446   \n3                  5        0.879420        0.877672        0.877320   \n4                  1        0.878912        0.876650        0.879349   \n5                  9        0.878802        0.873521        0.878049   \n6                  3        0.878912        0.877273        0.879638   \n7                  4        0.879310        0.876251        0.879819   \n8                  2        0.879420        0.876937        0.880145   \n9                  6        0.879420        0.876538        0.879638   \n10                11             NaN             NaN             NaN   \n11                12             NaN             NaN             NaN   \n12                13             NaN             NaN             NaN   \n13                14             NaN             NaN             NaN   \n14                15             NaN             NaN             NaN   \n\n    split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \n0         0.871564        0.883165      0.877413     0.003843            10  \n1         0.874887        0.885095      0.878595     0.003547             7  \n2         0.872695        0.886427      0.878546     0.004498             8  \n3         0.873480        0.887045      0.878987     0.004471             6  \n4         0.875000        0.887149      0.879412     0.004176             4  \n5         0.874381        0.885291      0.878009     0.004170             9  \n6         0.874887        0.887760      0.879694     0.004351             1  \n7         0.875788        0.886228      0.879479     0.003734             3  \n8         0.875506        0.886123      0.879626     0.003653             2  \n9         0.874887        0.885095      0.879115     0.003482             5  \n10             NaN             NaN           NaN          NaN            11  \n11             NaN             NaN           NaN          NaN            12  \n12             NaN             NaN           NaN          NaN            13  \n13             NaN             NaN           NaN          NaN            14  \n14             NaN             NaN           NaN          NaN            15  \n\n[15 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_criterion</th>\n      <th>param_n_estimators</th>\n      <th>params</th>\n      <th>split0_test_accuracy</th>\n      <th>split1_test_accuracy</th>\n      <th>split2_test_accuracy</th>\n      <th>...</th>\n      <th>std_test_recall</th>\n      <th>rank_test_recall</th>\n      <th>split0_test_f1</th>\n      <th>split1_test_f1</th>\n      <th>split2_test_f1</th>\n      <th>split3_test_f1</th>\n      <th>split4_test_f1</th>\n      <th>mean_test_f1</th>\n      <th>std_test_f1</th>\n      <th>rank_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.608557</td>\n      <td>0.064217</td>\n      <td>0.026259</td>\n      <td>0.008374</td>\n      <td>gini</td>\n      <td>50</td>\n      <td>{'criterion': 'gini', 'n_estimators': 50}</td>\n      <td>0.853420</td>\n      <td>0.856056</td>\n      <td>0.851168</td>\n      <td>...</td>\n      <td>0.002421</td>\n      <td>10</td>\n      <td>0.877161</td>\n      <td>0.879381</td>\n      <td>0.875793</td>\n      <td>0.871564</td>\n      <td>0.883165</td>\n      <td>0.877413</td>\n      <td>0.003843</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.539208</td>\n      <td>0.027788</td>\n      <td>0.051781</td>\n      <td>0.002160</td>\n      <td>gini</td>\n      <td>150</td>\n      <td>{'criterion': 'gini', 'n_estimators': 150}</td>\n      <td>0.854506</td>\n      <td>0.851711</td>\n      <td>0.854427</td>\n      <td>...</td>\n      <td>0.004618</td>\n      <td>8</td>\n      <td>0.878513</td>\n      <td>0.875965</td>\n      <td>0.878513</td>\n      <td>0.874887</td>\n      <td>0.885095</td>\n      <td>0.878595</td>\n      <td>0.003547</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.552853</td>\n      <td>0.081574</td>\n      <td>0.081552</td>\n      <td>0.002973</td>\n      <td>gini</td>\n      <td>250</td>\n      <td>{'criterion': 'gini', 'n_estimators': 250}</td>\n      <td>0.855049</td>\n      <td>0.852254</td>\n      <td>0.853884</td>\n      <td>...</td>\n      <td>0.004260</td>\n      <td>7</td>\n      <td>0.878802</td>\n      <td>0.876364</td>\n      <td>0.878446</td>\n      <td>0.872695</td>\n      <td>0.886427</td>\n      <td>0.878546</td>\n      <td>0.004498</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.694177</td>\n      <td>0.132688</td>\n      <td>0.116957</td>\n      <td>0.007010</td>\n      <td>gini</td>\n      <td>350</td>\n      <td>{'criterion': 'gini', 'n_estimators': 350}</td>\n      <td>0.855592</td>\n      <td>0.853884</td>\n      <td>0.852797</td>\n      <td>...</td>\n      <td>0.003142</td>\n      <td>5</td>\n      <td>0.879420</td>\n      <td>0.877672</td>\n      <td>0.877320</td>\n      <td>0.873480</td>\n      <td>0.887045</td>\n      <td>0.878987</td>\n      <td>0.004471</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.539945</td>\n      <td>0.106185</td>\n      <td>0.147498</td>\n      <td>0.004690</td>\n      <td>gini</td>\n      <td>450</td>\n      <td>{'criterion': 'gini', 'n_estimators': 450}</td>\n      <td>0.855049</td>\n      <td>0.852797</td>\n      <td>0.854970</td>\n      <td>...</td>\n      <td>0.004597</td>\n      <td>1</td>\n      <td>0.878912</td>\n      <td>0.876650</td>\n      <td>0.879349</td>\n      <td>0.875000</td>\n      <td>0.887149</td>\n      <td>0.879412</td>\n      <td>0.004176</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.747248</td>\n      <td>0.010979</td>\n      <td>0.020513</td>\n      <td>0.000602</td>\n      <td>entropy</td>\n      <td>50</td>\n      <td>{'criterion': 'entropy', 'n_estimators': 50}</td>\n      <td>0.855049</td>\n      <td>0.848995</td>\n      <td>0.853341</td>\n      <td>...</td>\n      <td>0.006065</td>\n      <td>9</td>\n      <td>0.878802</td>\n      <td>0.873521</td>\n      <td>0.878049</td>\n      <td>0.874381</td>\n      <td>0.885291</td>\n      <td>0.878009</td>\n      <td>0.004170</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.154744</td>\n      <td>0.074342</td>\n      <td>0.050961</td>\n      <td>0.000738</td>\n      <td>entropy</td>\n      <td>150</td>\n      <td>{'criterion': 'entropy', 'n_estimators': 150}</td>\n      <td>0.855049</td>\n      <td>0.853341</td>\n      <td>0.855513</td>\n      <td>...</td>\n      <td>0.004260</td>\n      <td>3</td>\n      <td>0.878912</td>\n      <td>0.877273</td>\n      <td>0.879638</td>\n      <td>0.874887</td>\n      <td>0.887760</td>\n      <td>0.879694</td>\n      <td>0.004351</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>5.432840</td>\n      <td>2.369643</td>\n      <td>0.115296</td>\n      <td>0.042988</td>\n      <td>entropy</td>\n      <td>250</td>\n      <td>{'criterion': 'entropy', 'n_estimators': 250}</td>\n      <td>0.855592</td>\n      <td>0.852254</td>\n      <td>0.856056</td>\n      <td>...</td>\n      <td>0.004355</td>\n      <td>4</td>\n      <td>0.879310</td>\n      <td>0.876251</td>\n      <td>0.879819</td>\n      <td>0.875788</td>\n      <td>0.886228</td>\n      <td>0.879479</td>\n      <td>0.003734</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.816453</td>\n      <td>0.958650</td>\n      <td>0.249620</td>\n      <td>0.047486</td>\n      <td>entropy</td>\n      <td>350</td>\n      <td>{'criterion': 'entropy', 'n_estimators': 350}</td>\n      <td>0.855592</td>\n      <td>0.853341</td>\n      <td>0.856056</td>\n      <td>...</td>\n      <td>0.005583</td>\n      <td>2</td>\n      <td>0.879420</td>\n      <td>0.876937</td>\n      <td>0.880145</td>\n      <td>0.875506</td>\n      <td>0.886123</td>\n      <td>0.879626</td>\n      <td>0.003653</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12.076668</td>\n      <td>2.160699</td>\n      <td>0.281048</td>\n      <td>0.082666</td>\n      <td>entropy</td>\n      <td>450</td>\n      <td>{'criterion': 'entropy', 'n_estimators': 450}</td>\n      <td>0.855592</td>\n      <td>0.852797</td>\n      <td>0.855513</td>\n      <td>...</td>\n      <td>0.005471</td>\n      <td>6</td>\n      <td>0.879420</td>\n      <td>0.876538</td>\n      <td>0.879638</td>\n      <td>0.874887</td>\n      <td>0.885095</td>\n      <td>0.879115</td>\n      <td>0.003482</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.029596</td>\n      <td>0.003211</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>log_loss</td>\n      <td>50</td>\n      <td>{'criterion': 'log_loss', 'n_estimators': 50}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.081283</td>\n      <td>0.007692</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>log_loss</td>\n      <td>150</td>\n      <td>{'criterion': 'log_loss', 'n_estimators': 150}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.132896</td>\n      <td>0.011402</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>log_loss</td>\n      <td>250</td>\n      <td>{'criterion': 'log_loss', 'n_estimators': 250}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.171306</td>\n      <td>0.012790</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>log_loss</td>\n      <td>350</td>\n      <td>{'criterion': 'log_loss', 'n_estimators': 350}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.234864</td>\n      <td>0.010317</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>log_loss</td>\n      <td>450</td>\n      <td>{'criterion': 'log_loss', 'n_estimators': 450}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n<p>15 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).to_csv(\"random_forest_gs_results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts_pred = d_tree.predict(ts)\n",
    "get_metrics(ts_target, ts_pred, ['genuine_user','bot'],'test')\n",
    "confusion_matrix(ts_target, ts_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(gs.cv_results_)\n",
    "results_df.to_csv(\"classification/random_forest/gs_results.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                                                                                                                   params  \\\n2879     {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n2849     {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 1, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n1657        {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}   \n1659        {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n1661         {'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}   \n...                                                                                                                                                                                                                   ...   \n4315     {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 8, 'random_state': 42, 'splitter': 'best'}   \n4316  {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'random'}   \n4317    {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}   \n4318  {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'random'}   \n4319    {'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}   \n\n      mean_train_accuracy  mean_train_precision  mean_train_recall  \\\n2879              0.85918              0.794242            0.99208   \n2849              0.85918              0.794242            0.99208   \n1657              0.85918              0.794242            0.99208   \n1659              0.85918              0.794242            0.99208   \n1661              0.85918              0.794242            0.99208   \n...                   ...                   ...                ...   \n4315                  NaN                   NaN                NaN   \n4316                  NaN                   NaN                NaN   \n4317                  NaN                   NaN                NaN   \n4318                  NaN                   NaN                NaN   \n4319                  NaN                   NaN                NaN   \n\n      mean_train_f1  mean_test_accuracy  mean_test_precision  \\\n2879       0.882203            0.859178             0.794396   \n2849       0.882203            0.859178             0.794396   \n1657       0.882203            0.859178             0.794396   \n1659       0.882203            0.859178             0.794396   \n1661       0.882203            0.859178             0.794396   \n...             ...                 ...                  ...   \n4315            NaN                 NaN                  NaN   \n4316            NaN                 NaN                  NaN   \n4317            NaN                 NaN                  NaN   \n4318            NaN                 NaN                  NaN   \n4319            NaN                 NaN                  NaN   \n\n      mean_test_recall  mean_test_f1  \n2879          0.992079      0.882259  \n2849          0.992079      0.882259  \n1657          0.992079      0.882259  \n1659          0.992079      0.882259  \n1661          0.992079      0.882259  \n...                ...           ...  \n4315               NaN           NaN  \n4316               NaN           NaN  \n4317               NaN           NaN  \n4318               NaN           NaN  \n4319               NaN           NaN  \n\n[4320 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_train_accuracy</th>\n      <th>mean_train_precision</th>\n      <th>mean_train_recall</th>\n      <th>mean_train_f1</th>\n      <th>mean_test_accuracy</th>\n      <th>mean_test_precision</th>\n      <th>mean_test_recall</th>\n      <th>mean_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2879</th>\n      <td>{'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>2849</th>\n      <td>{'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 1, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1657</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1659</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 2, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>1661</th>\n      <td>{'criterion': 'entropy', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 4, 'min_samples_split': 2, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>0.85918</td>\n      <td>0.794242</td>\n      <td>0.99208</td>\n      <td>0.882203</td>\n      <td>0.859178</td>\n      <td>0.794396</td>\n      <td>0.992079</td>\n      <td>0.882259</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4315</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 8, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4316</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'random'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4317</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 16, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4318</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'random'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4319</th>\n      <td>{'criterion': 'log_loss', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'min_samples_leaf': 8, 'min_samples_split': 32, 'random_state': 42, 'splitter': 'best'}</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4320 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by='mean_test_f1',ascending=False)[['params','mean_train_accuracy','mean_train_precision','mean_train_recall','mean_train_f1',\n",
    "            'mean_test_accuracy','mean_test_precision','mean_test_recall','mean_test_f1']]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "params = results_df.sort_values(by='mean_test_f1',ascending=False)['params'].head(1).reset_index().loc[0][1]\n",
    "r_forest = RandomForestClassifier(**params)\n",
    "r_forest = r_forest.fit(tr, tr_target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts_pred = r_forest.predict(ts)\n",
    "get_metrics(ts_target, ts_pred, ['genuine_user', 'bot'], 'test')\n",
    "confusion_matrix(ts_target, ts_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adaboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=4)],\n",
    "    'n_estimators': [8,16,32,64,128],\n",
    "    'learning_rate': [1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "    'algorithm': ['SAMME','SAMME.R'],\n",
    "}\n",
    "\n",
    "adaboost = AdaBoostClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "gs = GridSearchCV(adaboost, param_grid=parameters, scoring=['accuracy','precision','recall','f1'], verbose=3,refit=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.01, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=0.1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=1, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=10.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=8, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=16, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=32, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=64, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 1/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 2/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, base_estimator=DecisionTreeClassifier(max_depth=4), learning_rate=100.0, n_estimators=128, random_state=42; accuracy: (test=nan) f1: (test=nan) recall: (test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "250 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 678, in _fit_and_score\n",
      "    estimator.fit(X_train, **fit_params)\n",
      "TypeError: fit() missing 1 required positional argument: 'y'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\al\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(estimator=AdaBoostClassifier(),\n             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n                         'base_estimator': [DecisionTreeClassifier(max_depth=4)],\n                         'learning_rate': [0.01, 0.1, 1, 10.0, 100.0],\n                         'n_estimators': [8, 16, 32, 64, 128],\n                         'random_state': [42]},\n             refit=False, scoring=['accuracy', 'recall', 'f1'], verbose=3)"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(tr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.002901      0.000803              0.0             0.0   \n1        0.002055      0.000629              0.0             0.0   \n2        0.002208      0.001298              0.0             0.0   \n3        0.002409      0.001351              0.0             0.0   \n4        0.001309      0.000407              0.0             0.0   \n5        0.002921      0.001494              0.0             0.0   \n6        0.003811      0.001874              0.0             0.0   \n7        0.004641      0.001841              0.0             0.0   \n8        0.002541      0.000828              0.0             0.0   \n9        0.003745      0.001786              0.0             0.0   \n10       0.004111      0.002202              0.0             0.0   \n11       0.001907      0.000652              0.0             0.0   \n12       0.003378      0.002191              0.0             0.0   \n13       0.003207      0.001132              0.0             0.0   \n14       0.002618      0.001220              0.0             0.0   \n15       0.003511      0.001450              0.0             0.0   \n16       0.004921      0.001728              0.0             0.0   \n17       0.002056      0.000630              0.0             0.0   \n18       0.001892      0.001809              0.0             0.0   \n19       0.002438      0.001303              0.0             0.0   \n20       0.003416      0.002198              0.0             0.0   \n21       0.003010      0.001383              0.0             0.0   \n22       0.002307      0.001662              0.0             0.0   \n23       0.001804      0.000749              0.0             0.0   \n24       0.001770      0.001212              0.0             0.0   \n25       0.001492      0.000453              0.0             0.0   \n26       0.003514      0.001008              0.0             0.0   \n27       0.003925      0.001021              0.0             0.0   \n28       0.002656      0.001031              0.0             0.0   \n29       0.004327      0.001892              0.0             0.0   \n30       0.001546      0.000785              0.0             0.0   \n31       0.002329      0.000919              0.0             0.0   \n32       0.002666      0.001950              0.0             0.0   \n33       0.002924      0.001384              0.0             0.0   \n34       0.002037      0.001328              0.0             0.0   \n35       0.002521      0.001543              0.0             0.0   \n36       0.002526      0.001556              0.0             0.0   \n37       0.001864      0.001152              0.0             0.0   \n38       0.001602      0.000799              0.0             0.0   \n39       0.001589      0.000345              0.0             0.0   \n40       0.001398      0.000490              0.0             0.0   \n41       0.002033      0.000699              0.0             0.0   \n42       0.002495      0.000628              0.0             0.0   \n43       0.001729      0.001185              0.0             0.0   \n44       0.001793      0.000753              0.0             0.0   \n45       0.000947      0.000376              0.0             0.0   \n46       0.001479      0.000419              0.0             0.0   \n47       0.004441      0.002057              0.0             0.0   \n48       0.003417      0.002253              0.0             0.0   \n49       0.002783      0.001705              0.0             0.0   \n\n   param_algorithm                 param_base_estimator param_learning_rate  \\\n0            SAMME  DecisionTreeClassifier(max_depth=4)                0.01   \n1            SAMME  DecisionTreeClassifier(max_depth=4)                0.01   \n2            SAMME  DecisionTreeClassifier(max_depth=4)                0.01   \n3            SAMME  DecisionTreeClassifier(max_depth=4)                0.01   \n4            SAMME  DecisionTreeClassifier(max_depth=4)                0.01   \n5            SAMME  DecisionTreeClassifier(max_depth=4)                 0.1   \n6            SAMME  DecisionTreeClassifier(max_depth=4)                 0.1   \n7            SAMME  DecisionTreeClassifier(max_depth=4)                 0.1   \n8            SAMME  DecisionTreeClassifier(max_depth=4)                 0.1   \n9            SAMME  DecisionTreeClassifier(max_depth=4)                 0.1   \n10           SAMME  DecisionTreeClassifier(max_depth=4)                   1   \n11           SAMME  DecisionTreeClassifier(max_depth=4)                   1   \n12           SAMME  DecisionTreeClassifier(max_depth=4)                   1   \n13           SAMME  DecisionTreeClassifier(max_depth=4)                   1   \n14           SAMME  DecisionTreeClassifier(max_depth=4)                   1   \n15           SAMME  DecisionTreeClassifier(max_depth=4)                10.0   \n16           SAMME  DecisionTreeClassifier(max_depth=4)                10.0   \n17           SAMME  DecisionTreeClassifier(max_depth=4)                10.0   \n18           SAMME  DecisionTreeClassifier(max_depth=4)                10.0   \n19           SAMME  DecisionTreeClassifier(max_depth=4)                10.0   \n20           SAMME  DecisionTreeClassifier(max_depth=4)               100.0   \n21           SAMME  DecisionTreeClassifier(max_depth=4)               100.0   \n22           SAMME  DecisionTreeClassifier(max_depth=4)               100.0   \n23           SAMME  DecisionTreeClassifier(max_depth=4)               100.0   \n24           SAMME  DecisionTreeClassifier(max_depth=4)               100.0   \n25         SAMME.R  DecisionTreeClassifier(max_depth=4)                0.01   \n26         SAMME.R  DecisionTreeClassifier(max_depth=4)                0.01   \n27         SAMME.R  DecisionTreeClassifier(max_depth=4)                0.01   \n28         SAMME.R  DecisionTreeClassifier(max_depth=4)                0.01   \n29         SAMME.R  DecisionTreeClassifier(max_depth=4)                0.01   \n30         SAMME.R  DecisionTreeClassifier(max_depth=4)                 0.1   \n31         SAMME.R  DecisionTreeClassifier(max_depth=4)                 0.1   \n32         SAMME.R  DecisionTreeClassifier(max_depth=4)                 0.1   \n33         SAMME.R  DecisionTreeClassifier(max_depth=4)                 0.1   \n34         SAMME.R  DecisionTreeClassifier(max_depth=4)                 0.1   \n35         SAMME.R  DecisionTreeClassifier(max_depth=4)                   1   \n36         SAMME.R  DecisionTreeClassifier(max_depth=4)                   1   \n37         SAMME.R  DecisionTreeClassifier(max_depth=4)                   1   \n38         SAMME.R  DecisionTreeClassifier(max_depth=4)                   1   \n39         SAMME.R  DecisionTreeClassifier(max_depth=4)                   1   \n40         SAMME.R  DecisionTreeClassifier(max_depth=4)                10.0   \n41         SAMME.R  DecisionTreeClassifier(max_depth=4)                10.0   \n42         SAMME.R  DecisionTreeClassifier(max_depth=4)                10.0   \n43         SAMME.R  DecisionTreeClassifier(max_depth=4)                10.0   \n44         SAMME.R  DecisionTreeClassifier(max_depth=4)                10.0   \n45         SAMME.R  DecisionTreeClassifier(max_depth=4)               100.0   \n46         SAMME.R  DecisionTreeClassifier(max_depth=4)               100.0   \n47         SAMME.R  DecisionTreeClassifier(max_depth=4)               100.0   \n48         SAMME.R  DecisionTreeClassifier(max_depth=4)               100.0   \n49         SAMME.R  DecisionTreeClassifier(max_depth=4)               100.0   \n\n   param_n_estimators param_random_state  \\\n0                   8                 42   \n1                  16                 42   \n2                  32                 42   \n3                  64                 42   \n4                 128                 42   \n5                   8                 42   \n6                  16                 42   \n7                  32                 42   \n8                  64                 42   \n9                 128                 42   \n10                  8                 42   \n11                 16                 42   \n12                 32                 42   \n13                 64                 42   \n14                128                 42   \n15                  8                 42   \n16                 16                 42   \n17                 32                 42   \n18                 64                 42   \n19                128                 42   \n20                  8                 42   \n21                 16                 42   \n22                 32                 42   \n23                 64                 42   \n24                128                 42   \n25                  8                 42   \n26                 16                 42   \n27                 32                 42   \n28                 64                 42   \n29                128                 42   \n30                  8                 42   \n31                 16                 42   \n32                 32                 42   \n33                 64                 42   \n34                128                 42   \n35                  8                 42   \n36                 16                 42   \n37                 32                 42   \n38                 64                 42   \n39                128                 42   \n40                  8                 42   \n41                 16                 42   \n42                 32                 42   \n43                 64                 42   \n44                128                 42   \n45                  8                 42   \n46                 16                 42   \n47                 32                 42   \n48                 64                 42   \n49                128                 42   \n\n                                                                                                                                              params  \\\n0        {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 8, 'random_state': 42}   \n1       {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 16, 'random_state': 42}   \n2       {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 32, 'random_state': 42}   \n3       {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 64, 'random_state': 42}   \n4      {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 128, 'random_state': 42}   \n5         {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 8, 'random_state': 42}   \n6        {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 16, 'random_state': 42}   \n7        {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 32, 'random_state': 42}   \n8        {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 64, 'random_state': 42}   \n9       {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 128, 'random_state': 42}   \n10          {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 8, 'random_state': 42}   \n11         {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 16, 'random_state': 42}   \n12         {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 32, 'random_state': 42}   \n13         {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 64, 'random_state': 42}   \n14        {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 128, 'random_state': 42}   \n15       {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 8, 'random_state': 42}   \n16      {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 16, 'random_state': 42}   \n17      {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 32, 'random_state': 42}   \n18      {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 64, 'random_state': 42}   \n19     {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 128, 'random_state': 42}   \n20      {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 8, 'random_state': 42}   \n21     {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 16, 'random_state': 42}   \n22     {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 32, 'random_state': 42}   \n23     {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 64, 'random_state': 42}   \n24    {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 128, 'random_state': 42}   \n25     {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 8, 'random_state': 42}   \n26    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 16, 'random_state': 42}   \n27    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 32, 'random_state': 42}   \n28    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 64, 'random_state': 42}   \n29   {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 128, 'random_state': 42}   \n30      {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 8, 'random_state': 42}   \n31     {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 16, 'random_state': 42}   \n32     {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 32, 'random_state': 42}   \n33     {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 64, 'random_state': 42}   \n34    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 128, 'random_state': 42}   \n35        {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 8, 'random_state': 42}   \n36       {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 16, 'random_state': 42}   \n37       {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 32, 'random_state': 42}   \n38       {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 64, 'random_state': 42}   \n39      {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 128, 'random_state': 42}   \n40     {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 8, 'random_state': 42}   \n41    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 16, 'random_state': 42}   \n42    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 32, 'random_state': 42}   \n43    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 64, 'random_state': 42}   \n44   {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 128, 'random_state': 42}   \n45    {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 8, 'random_state': 42}   \n46   {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 16, 'random_state': 42}   \n47   {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 32, 'random_state': 42}   \n48   {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 64, 'random_state': 42}   \n49  {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 128, 'random_state': 42}   \n\n    ...  std_test_recall  rank_test_recall  split0_test_f1  split1_test_f1  \\\n0   ...              NaN                 1             NaN             NaN   \n1   ...              NaN                27             NaN             NaN   \n2   ...              NaN                28             NaN             NaN   \n3   ...              NaN                29             NaN             NaN   \n4   ...              NaN                30             NaN             NaN   \n5   ...              NaN                31             NaN             NaN   \n6   ...              NaN                32             NaN             NaN   \n7   ...              NaN                33             NaN             NaN   \n8   ...              NaN                34             NaN             NaN   \n9   ...              NaN                35             NaN             NaN   \n10  ...              NaN                36             NaN             NaN   \n11  ...              NaN                38             NaN             NaN   \n12  ...              NaN                49             NaN             NaN   \n13  ...              NaN                39             NaN             NaN   \n14  ...              NaN                40             NaN             NaN   \n15  ...              NaN                41             NaN             NaN   \n16  ...              NaN                42             NaN             NaN   \n17  ...              NaN                43             NaN             NaN   \n18  ...              NaN                44             NaN             NaN   \n19  ...              NaN                45             NaN             NaN   \n20  ...              NaN                46             NaN             NaN   \n21  ...              NaN                47             NaN             NaN   \n22  ...              NaN                48             NaN             NaN   \n23  ...              NaN                26             NaN             NaN   \n24  ...              NaN                25             NaN             NaN   \n25  ...              NaN                24             NaN             NaN   \n26  ...              NaN                23             NaN             NaN   \n27  ...              NaN                 2             NaN             NaN   \n28  ...              NaN                 3             NaN             NaN   \n29  ...              NaN                 4             NaN             NaN   \n30  ...              NaN                 5             NaN             NaN   \n31  ...              NaN                 6             NaN             NaN   \n32  ...              NaN                 7             NaN             NaN   \n33  ...              NaN                 8             NaN             NaN   \n34  ...              NaN                 9             NaN             NaN   \n35  ...              NaN                10             NaN             NaN   \n36  ...              NaN                11             NaN             NaN   \n37  ...              NaN                12             NaN             NaN   \n38  ...              NaN                13             NaN             NaN   \n39  ...              NaN                14             NaN             NaN   \n40  ...              NaN                15             NaN             NaN   \n41  ...              NaN                16             NaN             NaN   \n42  ...              NaN                17             NaN             NaN   \n43  ...              NaN                18             NaN             NaN   \n44  ...              NaN                19             NaN             NaN   \n45  ...              NaN                20             NaN             NaN   \n46  ...              NaN                21             NaN             NaN   \n47  ...              NaN                22             NaN             NaN   \n48  ...              NaN                37             NaN             NaN   \n49  ...              NaN                50             NaN             NaN   \n\n    split2_test_f1  split3_test_f1  split4_test_f1  mean_test_f1  std_test_f1  \\\n0              NaN             NaN             NaN           NaN          NaN   \n1              NaN             NaN             NaN           NaN          NaN   \n2              NaN             NaN             NaN           NaN          NaN   \n3              NaN             NaN             NaN           NaN          NaN   \n4              NaN             NaN             NaN           NaN          NaN   \n5              NaN             NaN             NaN           NaN          NaN   \n6              NaN             NaN             NaN           NaN          NaN   \n7              NaN             NaN             NaN           NaN          NaN   \n8              NaN             NaN             NaN           NaN          NaN   \n9              NaN             NaN             NaN           NaN          NaN   \n10             NaN             NaN             NaN           NaN          NaN   \n11             NaN             NaN             NaN           NaN          NaN   \n12             NaN             NaN             NaN           NaN          NaN   \n13             NaN             NaN             NaN           NaN          NaN   \n14             NaN             NaN             NaN           NaN          NaN   \n15             NaN             NaN             NaN           NaN          NaN   \n16             NaN             NaN             NaN           NaN          NaN   \n17             NaN             NaN             NaN           NaN          NaN   \n18             NaN             NaN             NaN           NaN          NaN   \n19             NaN             NaN             NaN           NaN          NaN   \n20             NaN             NaN             NaN           NaN          NaN   \n21             NaN             NaN             NaN           NaN          NaN   \n22             NaN             NaN             NaN           NaN          NaN   \n23             NaN             NaN             NaN           NaN          NaN   \n24             NaN             NaN             NaN           NaN          NaN   \n25             NaN             NaN             NaN           NaN          NaN   \n26             NaN             NaN             NaN           NaN          NaN   \n27             NaN             NaN             NaN           NaN          NaN   \n28             NaN             NaN             NaN           NaN          NaN   \n29             NaN             NaN             NaN           NaN          NaN   \n30             NaN             NaN             NaN           NaN          NaN   \n31             NaN             NaN             NaN           NaN          NaN   \n32             NaN             NaN             NaN           NaN          NaN   \n33             NaN             NaN             NaN           NaN          NaN   \n34             NaN             NaN             NaN           NaN          NaN   \n35             NaN             NaN             NaN           NaN          NaN   \n36             NaN             NaN             NaN           NaN          NaN   \n37             NaN             NaN             NaN           NaN          NaN   \n38             NaN             NaN             NaN           NaN          NaN   \n39             NaN             NaN             NaN           NaN          NaN   \n40             NaN             NaN             NaN           NaN          NaN   \n41             NaN             NaN             NaN           NaN          NaN   \n42             NaN             NaN             NaN           NaN          NaN   \n43             NaN             NaN             NaN           NaN          NaN   \n44             NaN             NaN             NaN           NaN          NaN   \n45             NaN             NaN             NaN           NaN          NaN   \n46             NaN             NaN             NaN           NaN          NaN   \n47             NaN             NaN             NaN           NaN          NaN   \n48             NaN             NaN             NaN           NaN          NaN   \n49             NaN             NaN             NaN           NaN          NaN   \n\n    rank_test_f1  \n0              1  \n1             27  \n2             28  \n3             29  \n4             30  \n5             31  \n6             32  \n7             33  \n8             34  \n9             35  \n10            36  \n11            38  \n12            49  \n13            39  \n14            40  \n15            41  \n16            42  \n17            43  \n18            44  \n19            45  \n20            46  \n21            47  \n22            48  \n23            26  \n24            25  \n25            24  \n26            23  \n27             2  \n28             3  \n29             4  \n30             5  \n31             6  \n32             7  \n33             8  \n34             9  \n35            10  \n36            11  \n37            12  \n38            13  \n39            14  \n40            15  \n41            16  \n42            17  \n43            18  \n44            19  \n45            20  \n46            21  \n47            22  \n48            37  \n49            50  \n\n[50 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_algorithm</th>\n      <th>param_base_estimator</th>\n      <th>param_learning_rate</th>\n      <th>param_n_estimators</th>\n      <th>param_random_state</th>\n      <th>params</th>\n      <th>...</th>\n      <th>std_test_recall</th>\n      <th>rank_test_recall</th>\n      <th>split0_test_f1</th>\n      <th>split1_test_f1</th>\n      <th>split2_test_f1</th>\n      <th>split3_test_f1</th>\n      <th>split4_test_f1</th>\n      <th>mean_test_f1</th>\n      <th>std_test_f1</th>\n      <th>rank_test_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.002901</td>\n      <td>0.000803</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.002055</td>\n      <td>0.000629</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>27</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002208</td>\n      <td>0.001298</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002409</td>\n      <td>0.001351</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>29</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001309</td>\n      <td>0.000407</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.002921</td>\n      <td>0.001494</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.003811</td>\n      <td>0.001874</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.004641</td>\n      <td>0.001841</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>33</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.002541</td>\n      <td>0.000828</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.003745</td>\n      <td>0.001786</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>35</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.004111</td>\n      <td>0.002202</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>36</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.001907</td>\n      <td>0.000652</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>38</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.003378</td>\n      <td>0.002191</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.003207</td>\n      <td>0.001132</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.002618</td>\n      <td>0.001220</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>40</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.003511</td>\n      <td>0.001450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>41</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.004921</td>\n      <td>0.001728</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>42</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.002056</td>\n      <td>0.000630</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>43</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.001892</td>\n      <td>0.001809</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>44</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.002438</td>\n      <td>0.001303</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>45</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.003416</td>\n      <td>0.002198</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>46</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.003010</td>\n      <td>0.001383</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>47</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.002307</td>\n      <td>0.001662</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>48</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.001804</td>\n      <td>0.000749</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.001770</td>\n      <td>0.001212</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.001492</td>\n      <td>0.000453</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.003514</td>\n      <td>0.001008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>23</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.003925</td>\n      <td>0.001021</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.002656</td>\n      <td>0.001031</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.004327</td>\n      <td>0.001892</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.01</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.01, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.001546</td>\n      <td>0.000785</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.002329</td>\n      <td>0.000919</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.002666</td>\n      <td>0.001950</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.002924</td>\n      <td>0.001384</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.002037</td>\n      <td>0.001328</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>0.1</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.002521</td>\n      <td>0.001543</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.002526</td>\n      <td>0.001556</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.001864</td>\n      <td>0.001152</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.001602</td>\n      <td>0.000799</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.001589</td>\n      <td>0.000345</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>1</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 1, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.001398</td>\n      <td>0.000490</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.002033</td>\n      <td>0.000699</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.002495</td>\n      <td>0.000628</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>17</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.001729</td>\n      <td>0.001185</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.001793</td>\n      <td>0.000753</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>10.0</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 10.0, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>19</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.000947</td>\n      <td>0.000376</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>8</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 8, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>20</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.001479</td>\n      <td>0.000419</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>16</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 16, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.004441</td>\n      <td>0.002057</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>32</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 32, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>22</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.003417</td>\n      <td>0.002253</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>64</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 64, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.002783</td>\n      <td>0.001705</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>SAMME.R</td>\n      <td>DecisionTreeClassifier(max_depth=4)</td>\n      <td>100.0</td>\n      <td>128</td>\n      <td>42</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 100.0, 'n_estimators': 128, 'random_state': 42}</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>50</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n<p>50 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
